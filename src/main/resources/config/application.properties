server.port=9090
client-openai.key=${API_KEY}
client-openai.endpoint=${PROXY_ENDPOINT}
client-openai.model-deployment=${MODEL_DEPLOYMENT_ID}

prompt-execution.temperature=${TEMPERATURE:1.0}
prompt-execution.max-tokens=${MAX_TOKENS:1024}
